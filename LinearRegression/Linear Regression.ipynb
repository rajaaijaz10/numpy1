{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is one of the most fundamental algorithms in the Machine Learning world. It is the door to the magical world ahead.\n",
    "But before proceeding with the algorithm, let’s first discuss the lifecycle of any machine learning model. This diagram explains the creation of a Machine Learning model from scratch and then taking the same model further with hyperparameter tuning to increase its accuracy, deciding the deployment strategies for that model and once deployed setting up the logging and monitoring frameworks to generate reports and dashboards based on the client requirements. \n",
    "A typical lifecycle diagram for a machine learning model looks like:\n",
    "\n",
    "<img src=\"MLApplicationFlow_bold.PNG\" width= \"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take our discussion of Linear Regression further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Regression Analysis?\n",
    "\n",
    "Regression in statistics is the process of predicting a Label(or Dependent Variable) based on the features(Independent Variables) at hand. Regression is used for time series modelling and finding the causal effect relationship between the variables and forecasting. For example, the relationship between the stock prices of the company and various factors like customer reputation and company annual performance etc. can be studied using regression.\n",
    "\n",
    "\n",
    "Regression analysis is an important tool for analysing and modelling data. Here, we fit a curve/line to the data points, in such a manner that the differences between the distance of the actual data points from the plotted curve/line is minimum. The topic will be explained in detail in the coming sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The use of Regression\n",
    "\n",
    "Regression analyses the relationship between two or more features. Let’s take an example:\n",
    "\n",
    "Let’s suppose we want to make an application which predicts the chances of admission a student to a foreign university. In that case, the \n",
    "\n",
    "The benefits of using Regression analysis are as follows:\n",
    "\n",
    "   * It shows the significant relationships between the Lable (dependent variable) and the features(independent variable).\n",
    "   * It shows the extent of the impact of multiple independent variables on the dependent variable.\n",
    "   *  It can also measure these effects even if the variables are on a different scale.\n",
    "\n",
    "These features enable the data scientists to find the best set of independent variables for predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear Regression is one of the most fundamental and widely known Machine Learning Algorithms which people start with. Building blocks of a Linear Regression Model are:\n",
    "* Discreet/continuous independent variables\n",
    "* A best-fit regression line\n",
    "* Continuous dependent variable.\n",
    "i.e., A Linear Regression model predicts the dependent variable using a regression line based on the independent variables.\n",
    "The equation of the Linear Regression is:\n",
    "\n",
    "                                                Y=a+b*X + e \n",
    "\n",
    " Where,\n",
    " a is the intercept, \n",
    "b is the slope of the line, \n",
    "and e is the error term. \n",
    "The equation above is used to predict the value of the target variable based on the given predictor variable(s).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem statement:\n",
    "\n",
    "This data is about the amount spent on advertising through different channels like TV, Radio and Newspaper. The goal is to predict how the expense on each channel affects the sales and is there a way to optimise that sale?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('Advertising.csv') # Reading the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  radio  newspaper  sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # checking the first five rows from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the **features**?\n",
    "- TV: Advertising dollars spent on TV for a single product in a given market (in thousands of dollars)\n",
    "- Radio: Advertising dollars spent on Radio\n",
    "- Newspaper: Advertising dollars spent on Newspaper\n",
    "\n",
    "What is the **response**?\n",
    "- Sales: sales of a single product in a given market (in thousands of widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 5 columns):\n",
      "Unnamed: 0    200 non-null int64\n",
      "TV            200 non-null float64\n",
      "radio         200 non-null float64\n",
      "newspaper     200 non-null float64\n",
      "sales         200 non-null float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info() # printing the summary of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "TV            0\n",
       "radio         0\n",
       "newspaper     0\n",
       "sales         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum() # finding the count of missing values from different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's showcase the relationship between the feature and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "\n",
    "data.plot(kind='scatter', x='TV', y='sales', ax=axs[0], figsize=(16, 8))\n",
    "data.plot(kind='scatter', x='radio', y='sales', ax=axs[1])\n",
    "data.plot(kind='scatter', x='newspaper', y='sales', ax=axs[2])\n",
    "fig.savefig('testdata.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions about the data\n",
    "\n",
    "A generic question shall be: How the company should optimise the spends on advertising to maximise the sales?\n",
    "\n",
    "These general questions might lead you to more specific questions:\n",
    "1. What’s the relationship between ads and sales?\n",
    "2. How prominent is that relationship?\n",
    "3. Which ad types contribute to sales?\n",
    "4. How each ad contributes to sales?\n",
    "5. Can sales be predicted based on the expense of the advertisement?\n",
    "\n",
    "We will explore these questions below!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the relationship diagrams above, it can be observed that there seems to be a linear relationship between the features TV ad,  Radio ad and the sales is almost a linear one. A linear relationship typically looks like:\n",
    "<img src=\"LinearGraph.png\" width=\"300\">\n",
    "\n",
    "Hence, we can build a model using the Linear Regression Algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Simple Linear regression is a method for predicting a **quantitative response** using a **single feature** (\"input variable\"). The mathematical equation is:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "What do terms represent?\n",
    "- $y$ is the response or the target variable\n",
    "- $x$ is the feature\n",
    "- $\\beta_1$ is the coefficient of x\n",
    "- $\\beta_0$ is the intercept\n",
    "\n",
    "$\\beta_0$ and $\\beta_1$ are the **model coefficients**. To create a model, we must \"learn\" the values of these coefficients. And once we have the value of these coefficients, we can use the model to predict the Sales!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating (\"Learning\") Model Coefficients\n",
    "\n",
    "The coefficients are estimated using the **least-squares criterion**,  i.e., the best fit line has to be calculated that minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mathematics involved\n",
    "Take a quick look at the plot created. Now consider each point, and know that each of them has a coordinate in the form (X, Y). Now draw an imaginary line between each point and the current \"best-fit\" line. We'll call the distance between each point and the current best-fit line as D. To get a quick image of what we're trying to visualize, take a look at the picture below:\n",
    "\n",
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/220px-Linear_least_squares_example2.svg.png\">\n",
    "\n",
    "What elements are present in the diagram?\n",
    "- The red points are the **observed values** of x and y.\n",
    "- The blue line is the **least squares line**.\n",
    "- The green lines are the **residuals**, which is the distance between the observed values and the least squares line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we're labelling each green line as having a distance D, and each red point as having a coordinate of (X, Y). Then we can define our best fit line as the line having the property were:\n",
    "$$ D_{1}^2 + D_{2}^2 + D_{3}^2 + D_{4}^2 + ....+ D_{N}^2$$\n",
    "\n",
    "So how do we find this line? The least-square line approximating the set of points:\n",
    "\n",
    "$$ (X,Y)_{1},(X,Y)_{2},(X,Y)_{3},(X,Y)_{4},(X,Y)_{5}, $$\n",
    "\n",
    "has the equation:\n",
    "$$ Y = a_{0} +a_{1}X $$\n",
    "this is basically just a rewritten form of the standard equation for a line:\n",
    "$$Y=mx+b$$\n",
    "\n",
    "We can solve for these constants a0 and a1 by simultaneously solving these equations:\n",
    "$$ \\Sigma Y = a_{0}N + a_{1}\\Sigma X $$\n",
    "$$ \\Sigma XY = a_{0}\\Sigma X + a_{1}\\Sigma X^2 $$\n",
    "These are called the normal equations for the least-squares line. There are further steps that can be taken in rearranging these equations to solve for y, but we'll let scikit-learn do the rest of the heavy lifting here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see the underlying assumptions: -\n",
    "* The regression model is linear in terms of coefficients and error term.\n",
    "* The mean of the residuals is zero.\n",
    "* The error terms are not correlated with each other, i.e. given an error value; we cannot predict the next error value.\n",
    "* The independent variables(x) are uncorrelated with the residual term, also termed as **exogeneity**. This, in layman term, generalises that in no way should the error term be predicted given the value of independent variables.\n",
    "* The error terms have a constant variance, i.e. **homoscedasticity**.\n",
    "* No Multicollinearity, i.e. no independent variables should be correlated with each other or affect one another. If there is multicollinearity, the precision of prediction by the OLS model decreases.\n",
    "* The error terms are normally distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general equation of a straight line is:$$𝑦={mx+b}$$\n",
    "It means that if we have the value of m and b, we can predict all the values of y for corresponding x.\n",
    "During construction of a Linear Regression Model, the computer tries to calculate the values of m and b to get a straight line.\n",
    "But the question is:\n",
    "###### How Do you Know this is the best fit line?\n",
    "The best fit line is obtained by minimizing the _residual_.\n",
    "Residual is the distance between the actual Y and the predicted Y, as shown below:\n",
    "<img src=\"residual.png\" width=\"300\">\n",
    "Mathematically, Residual is: $$r={y-(mx+b)}$$\n",
    "Hence, the sum of the square of residuals is:\n",
    "<img src=\"sumOfResiduals.png\" width=\"300\">\n",
    "\n",
    "As we can see that the residual is both a function of m and b, so differentiating partially with respect to m and b will give us:\n",
    "<img src=\"partialDerivatives.png\" width=\"300\">\n",
    "\n",
    "For getting the best fit line, residual should be minimum. The minima of a function occurs where the derivative=0. So, equating our corresponding derivatives to 0, we get:\n",
    "<img src=\"minima.png\" width=\"300\">\n",
    "\n",
    "This same equation can be written in matrix form as:\n",
    "<img src=\"matrix1.png\" width=\"300\">\n",
    "\n",
    "Ideally, if we'd have an equation of one dependent and one independent variable the minima will look as follows:\n",
    "<img src=\"minima2.png\" width=\"300\">\n",
    "\n",
    "But as the residual's minima is dependent on two variables m and b, it becomes a _Paraboloid_ and the appropriate m and b are calculated using _*Gradient Descent*_ as shown below:\n",
    "<img src=\"GradientDescent.gif\" width=\"300\"> Photo:Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s understand how to check, how well the model fits our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new values for 'slope' and 'intercept' are caluclated as follows:\n",
    "\n",
    "<img src=\"new_m.PNG\" width=\"300\">\n",
    "\n",
    "where, $\\theta_0$ is 'intercept' , $\\theta_1$ is the slope, $\\alpha$ is the learning rate, m is the total number of observations and the term after the $\\sum$ sign is the loss. Google Tensor board recommends a Learning rate between 0.00001 and 10. Generally a smaller learning rate is recommended to avoid overshooting while creating a model.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$ statistics\n",
    "\n",
    "The R-squared statistic provides a measure of fit. It takes the form of a proportion—the proportion of variance\n",
    "explained—and so it always takes on a value between 0 and 1. \n",
    "In simple words, it represents how much of our data is being explained by our model. \n",
    "For example,  $R^2$ statistic = 0.75, it says that our model fits 75 % of the total data set.\n",
    "Similarly, if it is 0, it means none of the data points is being explained and a value of 1 represents 100% data explanation.\n",
    "Mathematically $R^2$ statistic is calculated as :\n",
    "<img src=\"RSquared.PNG\" width=\"300\">\n",
    "                                              \n",
    "Where RSS:  is  the Residual Sum of squares and is given as :\n",
    "<img src=\"RSS.PNG\">\n",
    "                                                                \n",
    "RSS is the residual(error) term we have been talking about so far.\n",
    "And, TSS:  is  the Total sum of squares and given as :\n",
    "<img src=\"TSS.PNG\">\n",
    "                                                             \n",
    "TSS is calculated when we consider the line passing through the mean value of y, to be the best fit line.\n",
    "Just like RSS, we calculate the error term when the best fit line is the line passing through the mean value of y and we get the value of TSS.\n",
    "    <img src=\"TSS2.PNG\">\n",
    "    \n",
    "The closer the value of R2 is to 1 the better the model fits our data. If R2 comes below 0(which is a possibility) that means the model is so bad that it is performing even worse than the average best fit line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted $R^2$ statistics\n",
    "As we increase the number of independent variables in our equation, the R2 increases as well. But that doesn’t mean that the new independent variables have any correlation with the output variable. In other words, even with the addition of new features in our model, it is not necessary that our model will yield better results but R2 value will increase. To rectify this problem, we use Adjusted R2 value which penalises excessive use of such features which do not correlate with the output data.\n",
    "Let’s understand this with an example:\n",
    " \n",
    "<img src=\"adjr.PNG\" width=\"300\">\n",
    "We can see that R2 always increases with an increase in the number of independent variables.\n",
    "Thus, it doesn’t give a better picture and so we need Adjusted R2 value to keep this in check.\n",
    "Mathematically, it is calculated as:\n",
    "                                        <img src=\"adjr2.PNG\">\n",
    "In the equation above, when p = 0, we can see that adjusted R2 becomes equal to R2.\n",
    "Thus, adjusted R2  will always be less than or equal to R2, and it penalises the excess of independent variables which do not affect the dependent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.032593549127695\n",
      "[0.04753664]\n"
     ]
    }
   ],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV']\n",
    "X = data[feature_cols]\n",
    "y = data.sales\n",
    "\n",
    "# follow the usual sklearn pattern: import, instantiate, fit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print intercept and coefficients\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the model\n",
    "\n",
    "How do we interpret the coefficient for spends on TV ad ($\\beta_1$)?\n",
    "- A \"unit\" increase in spends on a TV ad is **associated with** a 0.047537 \"unit\" increase in Sales.\n",
    "- Or, an additional $1,000  on TV ads is **translated to** an increase in sales by 47.53 Dollars.\n",
    "\n",
    "As an increase in TV ad expenditure is associated with a **decrease** in sales, $\\beta_1$ would be **negative**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction  using the model\n",
    "\n",
    "If the expense on TV ad is $50000, what will be the sales prediction for that market?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 7.032594 + 0.047537 \\times 50$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.409444"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the prediction\n",
    "7.032594 + 0.047537*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we would predict Sales of **9,409 widgets** in that market.\n",
    "\n",
    "Let's do the same thing using code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TV\n",
       "0  50"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Let's create a DataFrame since the model expects it\n",
    "X_new = pd.DataFrame({'TV': [50]})\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.40942557])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the model to make predictions on a new value\n",
    "lm.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Least Squares Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame with the minimum and maximum values of TV\n",
    "X_new = pd.DataFrame({'TV': [data.TV.min(), data.TV.max()]})\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for those x values and store them\n",
    "preds = lm.predict(X_new)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, plot the observed data\n",
    "data.plot(kind='scatter', x='TV', y='sales')\n",
    "\n",
    "# then, plot the least squares line\n",
    "plt.plot(X_new, preds, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Confidence\n",
    "\n",
    "**Question:** Is linear regression a low bias/high variance model or a high bias/low variance model?\n",
    "\n",
    "**Answer:** It's a High bias/low variance model. Even after repeated sampling, the best fit line will stay roughly in the same position (low variance), but the average of the models created after repeated sampling won't do a great job in capturing the perfect relationship (high bias). Low variance is helpful when we don't have less training data! \n",
    "\n",
    "If the model has calculated a 95% confidence for our model coefficients, it can be interpreted as follows: \n",
    "If the population from which this sample is drawn, is **sampled 100 times**, then approximately **95 (out of 100) of those confidence intervals** shall contain the \"true\" coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "lm = smf.ols(formula='sales ~ TV', data=data).fit()\n",
    "lm.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that we only have a **single sample of data**, and not the **entire population of data**. The \"true\" coefficient is either within this interval or it isn't, but there's no way actually to know. We estimate the coefficient with the data we do have, and we show uncertainty about that estimate by giving a range that the coefficient is **probably** within.\n",
    "\n",
    "Note that using 95% confidence intervals is just a convention. You can create 90% confidence intervals (which will be more narrow), 99% confidence intervals (which will be wider), or whatever intervals you like.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing and p-values\n",
    "\n",
    "**Hypothesis testing** is Closely related to confidence intervals. We start with a **null hypothesis** and an **alternate hypothesis** (that is opposite to the null). Then, we check whether the data **rejects the null hypothesis** or **fails to reject the null hypothesis**.\n",
    "\n",
    "(\"Failing to reject\" the null hypothesis does not mean \"accepting\" the null hypothesis. The alternative hypothesis might indeed be true, but that we just don't have enough data to prove that.)\n",
    "\n",
    "The conventional hypothesis test is as follows:\n",
    "- **Null hypothesis:** No relationship exists between TV advertisements and Sales (and hence $\\beta_1$ equals zero).\n",
    "- **Alternative hypothesis:** There exists a relationship between TV advertisements and Sales (and hence, $\\beta_1$ is not equal to zero).\n",
    "\n",
    "How do we test this? We reject the null hypothesis (and thus believe the alternative hypothesis) if the 95% confidence interval **does not include zero**. The **p-value** represents the probability of the coefficient actually being zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the p-values for the model coefficients\n",
    "lm.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the 95% confidence interval **includes zero**, the p-value for that coefficient will be **greater than 0.05**. If the 95% confidence interval **does not include zero**, the p-value will be **less than 0.05**. \n",
    "\n",
    "Thus, a p-value of less than 0.05 is a way to decide whether there is any relationship between the feature in consideration and the response or not. Using 0.05 as the cutoff is just a convention.\n",
    "\n",
    "In this case, the p-value for TV ads is way less than 0.05, and so we **believe** that there is a relationship between TV advertisements and Sales.\n",
    "\n",
    "Note that we generally ignore the p-value for the intercept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Well Does the Model Fit the data?\n",
    "\n",
    "One of the most generic way to evaluate the fit of a linear model is by computing the **R-squared** value. R-squared explains the**proportion of variance**, i.e., the proportion of variance in the observed data which the model explains, or the reduction in error over the **null model**. (A null model only predicts the mean of all the observed responses, and thus it only has an intercept and no slope.)\n",
    "\n",
    "The value of R-squared lies between 0 and 1. A value closer to 1 is better as it means that more variance is explained by the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the R-squared value for the model\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it a \"good\" R-squared value? Now, that’s hard to say. In reality, the domain to which the data belongs to plays a significant role in deciding the threshold for the R-squared value. Therefore, it's a tool for **comparing different models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "Till now, we have created the model based on only one feature. Now, we’ll include multiple features and create a model to see the relationship between those features and the label column.\n",
    "This is called **Multiple Linear Regression**.\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient. In this case:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$\n",
    "\n",
    "Let's use Statsmodels to estimate these coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "X = data[feature_cols]\n",
    "y = data.sales\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print intercept and coefficients\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret these coefficients? \n",
    "If we look at the coefficients, the coefficient for the newspaper spends is negative. It means that the money spent for newspaper advertisements is not contributing in a positive way to the sales.\n",
    "\n",
    "A lot of the information we have been reviewing piece-by-piece is available in the model summary output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = smf.ols(formula='sales ~ TV + radio + newspaper', data=data).fit()\n",
    "lm.conf_int()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the things to be learnt from this summary?\n",
    "\n",
    "- TV and Radio have positive **p-values**, whereas Newspaper has a negative one. Hence, we can reject the null hypothesis for TV and Radio that there is no relation between those features and Sales, but we fail to reject the null hypothesis for Newspaper that there is no relationship between newspaper spends and sales.\n",
    "- The expenses on bot TV and Radio ads are**positively associated** with Sales, whereas the expense on newspaper ad is **slightly negatively associated** with the Sales.\n",
    "- This model has a higher value of **R-squared** (0.897) than the previous model, which means that this model explains more variance and provides a better fit to the data than a model that only includes the TV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "How do I decide **which features have to be included** in a linear model? Here's one idea:\n",
    "- Try different models, and only keep predictors in the model if they have small p-values.\n",
    "- Check if the R-squared value goes up when you add new predictors to the model.\n",
    "\n",
    "What are the **drawbacks** in this approach?\n",
    "-If the underlying assumptions for creating a Linear model(the features being independent) are violated(which usually is the case),p-values and R-squared values are less reliable.\n",
    "- Using a p-value cutoff of 0.05 means that adding 100 predictors to a model that are **pure noise**, still 5 of them (on average) will be counted as significant.\n",
    "- R-squared is susceptible to **model overfitting**, and thus there is no guarantee that a model with a high R-squared value will generalise. Following is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include TV and Radio in the model\n",
    "lm = smf.ols(formula='sales ~ TV + radio', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Newspaper to the model (which we believe has no association with Sales)\n",
    "lm = smf.ols(formula='sales ~ TV + radio + newspaper', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the model with the highest value of R-squared is not a correct approach as the value of R-squared shall always increase whenever a new feature is taken for consideration even if the feature is unrelated to the response.\n",
    "\n",
    "The alternative is to use **adjusted R-squared** which penalises the model complexity (to control overfitting), but this again generally [under-penalizes complexity](http://scott.fortmann-roe.com/docs/MeasuringError.html).\n",
    "\n",
    "a better approach to feature selection is**Cross-validation.** It provides a more reliable way to choose which of the created models will best **generalise** as it better estimates of out-of-sample error. An advantage is that the cross-validation method can be applied to any machine learning model and the scikit-learn package provides extensive functionality for that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization \n",
    "When we use regression models to train some data, there is a good chance that the model will overfit the given training data set.  Regularization helps sort this overfitting problem by restricting the degrees of freedom of a given equation i.e. simply reducing the number of degrees of a polynomial function by reducing their corresponding weights.  \n",
    "In a linear equation, we do not want huge weights/coefficients as a small change in weight can make a large difference for the dependent variable (Y). So, regularization constraints the weights of such features to avoid overfitting. Simple linear regression is given as:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x1+ \\beta_2x2 +\\beta_3x3+...+\\beta_PxP$\n",
    "\n",
    "Using the OLS method, we try to minimize the cost function given as:\n",
    "\n",
    "<img src=\"RSS_reg.PNG\" width=\"300\">\n",
    "\n",
    "To regularize the model, a Shrinkage penalty is added to the cost function.\n",
    "Let’s see different types of regularizations in regression:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO(Least Absolute Shrinkage and Selection Operator) Regression (L1 Form)\n",
    "LASSO regression penalizes the model based on the sum of magnitude of the coefficients. The regularization term is given by\n",
    "\n",
    " regularization=$ \\lambda *\\sum  |\\beta_j| $\n",
    "\n",
    "Where, λ is the shrinkage factor.\n",
    "\n",
    "and hence the formula for loss after regularization is:\n",
    "\n",
    "<img src=\"L1.PNG\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression (L2 Form)\n",
    "Ridge regression penalizes the model based on the sum of squares of magnitude of the coefficients. The regularization term is given by\n",
    "\n",
    " regularization=$ \\lambda *\\sum  |\\beta_j ^ 2| $\n",
    "\n",
    "Where, λ is the shrinkage factor.\n",
    "\n",
    "and hence the formula for loss after regularization is:\n",
    "\n",
    "<img src=\"ridge.PNG\" width=\"300\">\n",
    "\n",
    "This value of lambda can be anything and should be calculated by cross validation as to what suits the model.\n",
    "\n",
    "Let’s consider $\\beta_1$ and $\\beta_2$ be coefficients of a linear regression and λ = 1:\n",
    "\n",
    "For Lasso, $\\beta_1$ + $\\beta_2$ <= s  \n",
    "\n",
    "For Ridge, $\\beta_1^2$ + $\\beta_2^2$  <= s  \n",
    "\n",
    "Where s is the maximum value the equations can achieve\n",
    ".\n",
    "If we plot both the above equations, we get the following graph:\n",
    "\n",
    "<img src=\"ridge_vs_lasso.PNG\" width=\"300\">\n",
    "\n",
    "The red ellipse represents the cost function of the model, whereas the square (left side) represents the Lasso regression and the circle (right side) represents the Ridge regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Difference between Ridge and Lasso\n",
    "Ridge regression shrinks the coefficients for those predictors which contribute very less in the model but have huge weights, very close to zero. But it never makes them exactly zero. Thus, the final model will still contain all those predictors, though with less weights. This doesn’t help in interpreting the model very well. This is where Lasso regression differs with Ridge regression. In Lasso, the L1 penalty does reduce some coefficients exactly to zero when we use a sufficiently large tuning parameter λ. So, in addition to regularizing, lasso also performs feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why use Regularization?\n",
    "Regularization helps to reduce the variance of the model, without a substantial increase in the bias. If there is variance in the model that means that the model won’t fit well for dataset different that training data. The tuning parameter λ controls this bias and variance tradeoff. When the value of λ is increased up to a certain limit, it reduces the variance without losing any important properties in the data. But after a certain limit, the model will start losing some important properties which will increase the bias in the data. Thus, the selection of good value of λ is the key.\n",
    "The value of λ is selected using cross-validation methods. A set of λ is selected and cross-validation error is calculated for each value of λ and that value of λ is selected for which the cross-validation error is minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elastic Net\n",
    "\n",
    "According to the Hands-on Machine Learning book, elastic Net is a middle ground between Ridge Regression and Lasso Regression. The regularization term is a simple mix of both Ridge and Lasso’s regularization terms, and you can control the mix ratio α. \n",
    "\n",
    "<img src=\"elasticNet.PNG\" width=\"300\">\n",
    "where α is the mixing parameter between ridge (α = 0) and lasso (α = 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When should you use plain Linear Regression (i.e., without any regularization), Ridge, Lasso, or Elastic Net?**\n",
    "\n",
    "According to the Hands-on Machine Learning book, it is almost always preferable to have at least a little bit of regularization, so generally you should avoid plain Linear Regression. Ridge is a good default, but if you suspect that only a few features are actually useful, you should prefer Lasso or Elastic Net since they tend to reduce the useless features’ weights down to zero as we have discussed. In general, Elastic Net is preferred over Lasso since Lasso may behave erratically when the number of features is greater than the number of\n",
    "training instances or when several features are strongly correlated.\n",
    "\n",
    "No let's see the Python Implementation of these concepts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start with importing necessary libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2(x,y):\n",
    "    r2 = regression.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv('Admission_Prediction.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['University Rating'] = data['University Rating'].fillna(data['University Rating'].mode()[0])\n",
    "data['TOEFL Score'] = data['TOEFL Score'].fillna(data['TOEFL Score'].mean())\n",
    "data['GRE Score']  = data['GRE Score'].fillna(data['GRE Score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data looks good and there are no missing values. Also, the first cloumn is just serial numbers, so we don' need that column. Let's drop it from data and make it more clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop(columns = ['Serial No.'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data and analyze the relationship between independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=16 :\n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.distplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        #plt.ylabel('Salary',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data distribution looks decent enough and there doesn't seem to be any skewness. Great let's go ahead!\n",
    "\n",
    "Let's observe the relationship between independent variables and dependent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Chance of Admit']\n",
    "X =data.drop(columns = ['Chance of Admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,30), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in X:\n",
    "    if plotnumber<=15 :\n",
    "        ax = plt.subplot(5,3,plotnumber)\n",
    "        plt.scatter(X[column],y)\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        plt.ylabel('Chance of Admit',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, the relationship between the dependent and independent variables look fairly linear.\n",
    "Thus, our linearity assumption is satisfied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and use linear regression and see how good it fits our data.\n",
    "But first. let's split our data in train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_scaled,y,test_size = 0.25,random_state=355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "\n",
    "regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model to the local file system\n",
    "filename = 'finalized_model.pickle'\n",
    "pickle.dump(regression, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction using the saved model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "a=loaded_model.predict(scaler.transform([[300,110,5,5,5,10,1]]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_r2(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our r2 score is 84.15% and adj r2 is 83.85% for our training et., so looks like we are not being penalized by use of any feature.\n",
    "\n",
    "Let's check how well model fits the test data.\n",
    "\n",
    "Now let's check if our model is overfitting our data using regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_r2(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like our model r2 score is less on the test data.\n",
    "\n",
    "Let's see if our model is overfitting our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regularization\n",
    "# LassoCV will return best alpha and coefficients after performing 10 cross validations\n",
    "lasscv = LassoCV(alphas = None,cv =10, max_iter = 100000, normalize = True)\n",
    "lasscv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best alpha parameter\n",
    "alpha = lasscv.alpha_\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have best parameter, let's use Lasso regression and see how well our data has fitted before\n",
    "\n",
    "lasso_reg = Lasso(alpha)\n",
    "lasso_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our r2_score for test data (75.34%) comes same as before using regularization. So, it is fair to say our OLS model did not overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Ridge regression model\n",
    "# RidgeCV will return best alpha and coefficients after performing 10 cross validations. \n",
    "# We will pass an array of random numbers for ridgeCV to select best alpha from them\n",
    "\n",
    "alphas = np.random.uniform(low=0, high=10, size=(50,))\n",
    "ridgecv = RidgeCV(alphas = alphas,cv=10,normalize = True)\n",
    "ridgecv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=ridgecv.alpha_)\n",
    "ridge_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got the same r2 square using Ridge regression as well. So, it's safe to say there is no overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic net\n",
    "\n",
    "elasticCV = ElasticNetCV(alphas = None, cv =10)\n",
    "\n",
    "elasticCV.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticCV.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_ration gives how close the model is to L1 regularization, below value indicates we are giving equal\n",
    "#preference to L1 and L2\n",
    "elasticCV.l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_reg = ElasticNet(alpha = elasticCV.alpha_,l1_ratio=0.5)\n",
    "elasticnet_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see by using different type of regularization, we still are getting the same r2 score. That means our OLS model has been well trained over the training data and there is no overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
